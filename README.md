# GradientDescent

to update the weights and bias of our AI model and also minimize the average loss of our model

a warm introduction to "epochs" and "learning rate"!

a working example of the math behind Gradient Descent, and learn how to implement it with code by using our superior Python skills! 🐍🐍🐍

make sure you are proficient with the previous topics of my AI series - Perceptron, Weights, Input, Weighted Sum, Target, Prediction, Activation Function, Loss Function & Cross-Entropy Loss.

Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression).
