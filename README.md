# GradientDescent

to update the weights and bias of our AI model and also minimize the average loss of our model

a warm introduction to "epochs" and "learning rate"!

a working example of the math behind Gradient Descent, and learn how to implement it with code by using our superior Python skills! ğŸğŸğŸ

make sure you are proficient with the previous topics of my AI series - Perceptron, Weights, Input, Weighted Sum, Target, Prediction, Activation Function, Loss Function & Cross-Entropy Loss.

Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression).
